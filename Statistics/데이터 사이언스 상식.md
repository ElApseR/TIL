# 데이터 사이언스 상식

*이 글은 <a href="https://zzsza.github.io/data/2018/02/17/datascience-interivew-questions/#%EB%94%A5%EB%9F%AC%EB%8B%9D">데이터 사이언스 인터뷰 질문 모음집</a>에 짧게 답을 달아보는 글입니다.*

*좋은 참고자료 : <a href="https://developers.google.com/machine-learning/glossary/?hl=ko">구글 머신러닝 용어집</a>*

## 머신러닝

- **Cross Validation은 무엇이고 어떻게 해야하나요?**
    - 일반적으로 머신러닝에서 풀고자 하는 문제는 예측 문제이며, 이에 대해 모형의 성능을 정확히 파악하기 위해서는 학습에 사용하지 않은 데이터에 대한 모델의 예측력을 보아야한다. 이는 학습 데이터에서만 성능이 좋은 overfitting 문제가 있을 수 있기 때문이다. 이를 위해 학습에 사용할 데이터와 그렇지 않을 데이터를 나누어야할 필요성이 생기며, 학습에 사용하지 않은 데이터로 모델을 평가하는 것을 cross validation이라 한다. 하지만 데이터의 갯수가 적어서 딱 한 번 데이터의 일부를 제외하여 모델을 평가하기에는 신뢰성이 낮은 경우, 데이터를 k개의 조각으로 나누어(일반적으로 다섯 개) cross validation을 수행한 뒤, k번의 성능의 평균으로 모델의 성능을 평가하는 경우도 있다. 이를 k-fold cross validation이라 한다.
- **회귀 / 분류시 알맞은 metric은 무엇일까요? 알고 있는 metric에 대해 설명해주세요(ex. RMSE, MAE, recall, precision …)**
    - 우선 metric이란 우리의 모델의 성능을 평가하는 척도이다. 따라서 metric을 기준으로 모델을 학습할 수 있다면 최고겠으나, 그렇지 못한 다양한 경우가 발생하며 이 경우 loss function을 활용하곤 한다. 선형회귀는 metric을 기준으로 모델을 학습할 수 있는 좋은 경우이다. 일반적으로 선형회귀에서 회귀계수를 구할 때는 종속변수(y)의 MSE를 최소화 시키는 값을 찾는다. 또한 선형회귀식의 성능을 평가할 때 자주 쓰는 metric은 R-square인데 이는 MSE가 작아질 수록 그 값이 커진다(RMSE는 square root of mean squared error이며, 이를 metric으로 사용해도 MSE에서의 대소관계는 유지되므로 결과적으로 동일하다). 분류의 경우 모형의 목적에 따라 accuracy를 이용할 수도 있고, recall과 precision 또는 이를 동시에 볼 수 있는 f1 score를 이용하기도 한다. 가장 일반적으로는 f1 score를 이용하며, 이는 precision과 recall의 조화평균이다. precision은 참긍정/(참긍정+거짓긍정) 이며, recall은 참긍정/(참긍정+거짓부정)이다. 즉, precision은 모델이 true라고 예측한 값 중 실제 true의 비율이며, recall은 실제 true 중 모델이 true라고 예측한 비율이다.
- **정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?**
    - 정규화란 단어가 사실 한국말로 중의적이라 애매한데, 여기서는 regularization을 의미하는 것이라 생각하겠다. 일반적으로 머신러닝 모델의 성능은 bias variance trade off가 존재한다. bias가 큰 모델은 데이터의 특성을 전부 뽑아내지 못하고 underfit된 모델이다. 이와 달리 variance가 큰 모델은 training 데이터의 특성에 너무 과하게 맞춰진 overfit된 모델이다. bias가 큰 모델은 그 어떤 test 데이터에 대해서도 비슷한 성능을 보여준다는 장점이 있으나, 그 성능이 좋지 않다는 단점이 있다. variance가 큰 모델은 test 데이터가 바뀔 때마다 성능이 매우 크게 변동한다. 어떨 때는 엄청 좋다가 어떨 때는 엄청 구리다. 두 경우 모두 좋지 않다는 것은 분명하며, 우리는 모든 test set에 대해서 높은 성능을 일정하게 내주는 모델을 학습하길 원한다. Regularization은 overfit된(variance가 큰) 모델의 variance를 줄여준다. 그 방식은 L1정규화(parameter의 절대값의 합에 제약) L2정규화(parameter의 제곱합에 제약)이 있으며, L0정규화(parameter 갯수에 제약) 등의 방법도 존재한다. 즉, 일부러 train데이터에 좀더 underfit되게 만드는 것이다. 추가적으로 L1 정규화항이 있는 선형회귀식은 lasso 회귀라고 하며, feature selection에도 활용되곤 한다.
- **Local Minima와 Global Minima에 대해 설명해주세요.**
    - <img src="https://t1.daumcdn.net/cfile/tistory/9915A83E5AB8621703">
        - 출처 : <a href="https://gomguard.tistory.com/187">머신러닝[딥러닝] 뉴럴 네트워크 Part. 8 - 옵티마이저 (Optimizer)</a>
    - 모델을 학습하는 데에 위에 metric에서 언급하였듯이 loss function을 활용하는 경우가 다수 존재한다. 이때, loss function을 최소화하는 parameter를 optimization을 활용하여 구한다. 가장 많이 사용되는 optimization 방법인 gradient descent(경사하강법)은 각 parameter space에서 loss function이 줄어드는 방향으로 parameter를 일정량 이동시키는 방법이다. 이때, 만약 loss function의 생김새가 조그만 구덩이(local mimima)와 전체적으로 큰 구덩이(global minima)가 섞여있는 형태라면, 우리의 시작점이 어디인지에 따라 & 이동하는 크기가 얼마인지에 따라 조그만 구덩이에서 optimization이 끝나버리는 경우가 발생한다. 즉, 최고로 loss가 낮은 모델(global optima)이 되지 않고 애매하게 loss가 낮은 모델(local optima)이 만들어지는 것이다. 이를 해결하기 위해선 이동하는 크기(learning rate)와 optimizer를 바꾸어주어야 한다. 최근 딥러닝에서 가장 많이 사용하는 adam optimizer는 관성(방향)과 보폭(크기)을 함께 고려하는 방식을 사용한다.
- **차원의 저주란 무엇인가요?**
    - 테이블 형식의 데이터는 일반적으로 샘플의 갯수 n 과 feature의 갯수 p를 가지며 총 n*p 개의 cell을 가지고 있다. 여기서 n 대비 p의 갯수가 너무 많은 경우, 모델이 해당 데이터를 잘 학습하지 못하는 차원의 저주에 빠졌다고 말한다. 분류모델을 예로 들어보면, 분류모형이 데이터를 분류하는 법을 학습한다는 것은, 데이터가 존재하는 공간을 잘 나누는(선을 긋는) 법을 학습했다는 것을 의미한다. 만약 p의 갯수가 늘어난다면 모델이 나누어야할 공간의 크기가 그만큼 커진다는 의미인데, 모델이 선을 긋고자하는 부분에 데이터가 많이 없다면(밀도가 낮다면) 모델이 긋는 선의 위치가 부정확해질 수밖에 없을 것이다. 이것은 일반적으로 빅데이터란 단어를 통해 처음 데이터 사이언스를 접한 사람들이 헷갈려하는 지점 중 하나인데, 데이터의 갯수는 많으면 많을 수록 좋은 것은 아니라는 것을 다시 한 번 알려준다. 우리는 주어진 샘플 하에서 모델이 학습하기 적절한 차원의 크기를 설정해주어햐 한다.
- **dimension reduction기법으로 보통 어떤 것들이 있나요?**
    - 위와 연결되는 내용이다. 가장 일반적으로 사용되는 차원 축소 방법은 EDA를 통해 종속변수와 관련이 없는 것으로 판단되는 독립변수를 제거해주는 것이다. EDA는 데이터 분석의 전 과정에서 꾸준히 사용되므로 잘 알아두는 것이 중요하다. 또다른 일반적인 방법은 PCA가 있다. PCA는 원데이터가 존재하는 공간에서 데이터의 변동성을 가장 잘 보존하는 방향 벡터 하나씩을 뽑아내는 것이다. 일반적으로 모델링보다는 시각화 측면에서 좀더 자주 사용된다. 다른 방법으로는 L1 정규화를 사용하기도 한다. Lasso 회귀는 L1 정규화를 사용하는 대표적인 모델인데, L1 정규화의 특성상 설명력이 적은 변수를 제거해주는 특성이 있으며, 이를 이용하기도 한다.
- **PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 제거기법이기도 합니다. 왜 그런지 설명해주실 수 있나요?**
    - PCA는 데이터가 존재하는 공간에서 데이터의 변동성을 가장 잘 보존하는 방향 백터를 뽑아내는 방법이다. 만약 feature가 10 개인 데이터가 있는데, 10개의 방향벡터를 뽑는다면 이는 데이터의 변환일뿐, 데이터 자체는 그대로이다. 하지만 10개 미만의 방향 벡터를 뽑는다면 이때부터는 데이터의 축소가 된다. 데이터의 변동성을 가장 잘 보존하는 방향 벡터를 뽑는다는 것은, 가장 많은 정보를 함축할 수 있는 feature 순서대로 새로 만들겠다는 의미이다. 즉, 이를 순서대로 주워담으면 상대적으로 덜 중요하다고 여겨지는 것을 제거할 수 있는 것이다. 이에 따라 이는 데이터 압축기법이 될 수도 있고 노이즈 제거기법이 되기도 하는 것이다.
- **Batch Normalization의 효과는?**
    - Batch Normalization은 gradient vanishing/exploding이 발생하지 않도록 막는 방법이다. 기존에는 이를 막기 위해 activation function을 바꾸거나, weight initialization을 잘 하거나, learning rate를 낮추는 간접적인 방식으로 보완하려 했다. 하지만 이러한 현상의 본질적인 문제는 학습과정에서 각 layer보다 앞선 layer의 parameter가 변할 때마다 그 영향으로 input의 distribution이 달라지는 internal covariate shift이며, 이를 해결하려면 input의 분포를 계속 맞춰주는 해결책이 필요했다. 기존에는 단순히 정규화하는 whitening으로 이를 해결했으나, 이는 back propagation과 무관하게 진행된다는 단점이 있었다. Batch Normalization은 이를 보완하여, mini batch마다 평균/분산을 구하여 정규화를 수행하고 scale factor gamma를 곱하고 shift factor beta를 더해준다. Gamma와 beta는 activation function의 비선형성을 지켜주는 역할을 하며, 다른 parameter처럼 backprop을 통해 학습된다. 여기까지는 train 과정이며, test 과정에서는 mean과 variance를 mini batch에서 구하지 않고 기존에 train에서 구해둔 값의 평균으로 사용한다. gamma와 beta 역시 기존에 구해둔 값의 평균을 사용한다.
    - Dropout의 효과는?
        - Dropout은 뉴럴넷의 일부를 확률적으로 사용하지 않는 것을 의미한다. Dropout을 사용하느 이유는 뉴럴넷이 overfitting이 잘 되는 모델이기 때문에 이를 보완하기 위한 것이다. 즉 trainset에 대하여 일부러 문제를 더 어렵게 만드는 것이며, 이는 기존 머신러닝 모델에서 사용되는 regularization의 개념으로 볼 수 있다. 하지만 batch Normalization의 부수적인 효과로 regularization이 있기 때문에, Batch Normalization을 활용하는 경우에는 사용하지 않아도 된다는 연구 결과도 있다.
    - BN 적용해서 학습 이후 실제 사용시에 주의할 점은? 코드로는?
        - 위에 언급하였듯이 평균과 분산 및 gamma와 beta를 trainset에서 구해두어야한다. trainset의 mini batch에서 평균과 분산을 구하는 것은 mini batch의 내부적인 데이터 분포에 영향을 너무 크게 받기 때문이다.
    - GAN에서 Generator 쪽에도 BN을 적용해도 될까?
        - GAN의 가장 큰 문제점은 학습이 어렵다는 것이었는데, 이를 해결한 대표적인 state-of-the-art 논문이 DCGAN이다. DCGAN의 가장 큰 특징은 deconvolution을 쓴다는 것과 Batch Normalization을 쓴다는 것이다. 이를 통해 본다면 GAN의 Generator에도 BN을 적용해도 되지만, 최종 output layer에서는 적용해서는 안된다. 이는 G의 최종 output이 원래 데이터의 분포를 모방하고자 하는 것인데 BN은 오히려 이를 왜곡시킬 수 있기 때문이다.
- **요즘 max pooling 대신 stride가 2 이상인 CNN을 쓰기도 하는데 이유와 방법은?**
    - CNN은 convolution layer -> pooling layer -> activation layer 의 순서로 이루어지는 게 일반적이다. 이 중에서 pooling의 경우 일반적으로 max pooling을 활용하며, pooling 커널의 사이즈와 같은 크기의 stride를 적용한다. pooling을 쓰는 이유는 feature에 invariant한 네트워크를 만들며, 차원의 축소를 통해 큰 이미지의 경우도 적은 computational cost로 연산하기 위함이다. 하지만 max pooling은 가장 큰 값(또는 픽셀)만 살리는 방식이기 때문에 필연적으로 information loss가 발생한다. 따라서 이를 해결하기 위하여 **STRIVING FOR SIMPLICITY: THE ALL CONVOLUTIONAL NET** 이라는 논문은 pooling layer를 아예 제거하자고 주장한다. 그 방식은 크게 두 가지가 있는데, 첫째는 convolutional layer에서 stride를 늘리는 것이고, 둘째는 pooling layer를 또다른 convolutional layer로 바꾸는 것이다. 이는 convolutional layer를 한 번에 두 개씩 쌓자는 것이며, 두 번째 layer는 stride의 크기를 조정하여 원래 pooling시의 output의 차원과 맞춰준다. 이러한 방식은 선택된 max 값을 제외하고 버리는 것이 아니라, 주변의 모든 정보를 다 활용하기 때문에 정보의 손실이 적다는 장점이 있다.
