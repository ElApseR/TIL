# 잔디콘 후기
## nature of code
- 컴퓨터로 자연을 그리는 법
- 물리엔진 라이브러리 또는 게임개발 프레임워크에서 대다수의 기능을 제공하긴 한다.
    - 하지만 자연스러운 움직임, 화려한 효과를 표현할 알고리즘은 무수하다.
    - 그 기초를 알아보자
- random
    - perlin noise
        - 일반 랜덤과 다르게 부드러운(자연스러운) 곡선의 랜덤값을 내준다.
            - 약간 트랜드를 반영한 노이즈를 그려주는것
        - 평면에 픽셀 단위로 랜덤값을 페를린 노이즈로 주면 안개 같은 텍스쳐를 줄 수 있다.
- force
    - 어떤 물체의 움직임은 그 물체에 작용하는 여러 힘의 합으로 표현될 수 있다.
## causal inference
- 인과관계를 밝히는 법
- 실제 데이터 사이언스 직무를 하다보면
    - 원인 찾기
        - ex. 로그 수가 이유없이 떨어지네요
    - 효과 측정하기
        - 이번 업데이트가 매출에 얼마나 영향을 주었나요
- 우리가 배운 것은
    - 모델링을 통해 분류하고 예측하는 방법
- 일할 때 필요한 것은
    - 인과관계를 설명하는 방법
- 효과측정에 가장 많이 활용되는 것은 A/B test
    - 궁금한 변수 외의 나머지는 모두 고정해서 test 해보자
- A/B test가 불가능한 상황이 종종 발생한다.
    - 돈, 시간, 리소스 문제
    - 윤리적인 문제 및 이미 지나간 사건을 분석하고자 하는 경우
- 상관관계는 인과관계를 의미하지 않는다
    - 그럼 상관관계에 무엇을 추가해야 인과관계가 될 수 있는 것인가
- 인과관계와 효과를 설명하기 위한 다양한 방법(중 2개)
    - potential outcomes
        - 다른 모든 가능한 시나리오를 고려해서 그들의 결과를 보고, 현재의 결과와 비교하자
            - 다른 시나리오의 결과는 머신러닝 모델을 이용하여 추정한다.
                - 궁금한 포인트와 가장 유사한 조건의 포인트 데이터를 이용하여 추정한다.
            - ex. 케빈의 현재 손실이 삼바 투자로 인한 것인지 알고싶다.
                - 삼바에 투자하지 않았을 때의 금액을 예측해서 비교한다.
                - 케빈과 비슷한 조건을 가진 사람 중 삼바에 투자하지 않은 사람의 수익을 이용한다.
        - 개인 대 개인을 비교하면 힘드니까 유사한 특성을 가진 사람들끼리 그룹을 구성한다.
            - 해당 그룹의 평균을 사용한다.
        - 약간 knn 같은 느낌인 듯 -> 맞네
        - 특징
            - 상대적으로 직관적이며 친숙한 도구를 활용한다.
                - 인과관계 문제가 결측치 예측 문제로 바뀐다.
                - 모형보다는 데이터를 중심으로 추론한다.
                    - 상대적으로 쉬운 모형을 쓰며, 데이터가 중요하다.
            - 변수들의 관계를 고려하지 않고 기계적으로 예측해도 되는 것인가?
                - 친숙한 모델을 쓰는 것은 상관관계를 바탕으로 하는 방법론을 쓴다는 것
                    - 그럼 또 이것은 상관관계로 인과관계를 추론하는 것인디
                - 문제
                    - spurious correlation
                        - 서로 연관이  없어보이는 두 데이터가 높은 연관성을 보이는 경우가 있다.
                    - simpson’s paradox
                        - cofounder(교란변수)의 존재 때문
                        - 보통 이 경우 데이터를 잘게 쪼개서 보아야한다고 말하는데, 정말?
                            - 하위 그룹이 결과에 영향을 미칠만한 것이라면 쪼개서는 안된다
                    - perkson’s paradox
                        - 데이터를 쪼개는 게 능사가 아니라는 것을 보여주는 사례
                        - 통제된 데이터에서 얻은 상관관계가 잘못된 해석으로 이어질 수도 있다.
                        - 하위그룹이 우리가 궁금한 것의 결과라면. =>  collider
                            - 조건에 의한 편향
                        -
    - causal graphical models
        - 데이터만으로 추론하면 위에 언급된 함정에 빠지기 쉽다.
        - 우리가 가지고 있는 데이터들이 어떤 방식으로 생성되는지부터 고민해야한다
        - DAG(Directed Acyclic Graphs)를 통해 인과관계를 표현한다.
        - 그래프를 사용하면 결합확률분포를 효과적으로 표현할 수 있게 된다.
            - 그림을 그리면 확실히 눈에 잘 들어온다
        - 이것으로 하고자 하는 것
            - 원인과 결과(X->Y)
            - X에 변화를 주었을 때(개입) Y는 어떻게 변할까?
                - let P(Y|do(X))
            - P(Y|X)=P(Y|see(X))
                - 이건 우리가 X를 보았을 때 Y가 나타날 확률
                - 이것으로 상관관계와 인과관계를 구분지을 수 있음
        - 실험 없이 데이터만으로 P(Y|do(X))를 계산할 수 있을까?
            - X가 Y의 유일한 원인인 경우 -> 그런 경우는 거의 없음
            - Back-door Adjustment
            - Front door Adjustment
        - 따라서 그래프를 통해 back/front door adjustment가 먹히는 상황인지 보아야 한다.
## Text Classification
- text가 주어지면 그것의 label을 맞추는 문제
- 대부분의 NLP 분야는 text classification 분야에 기반을 두고 있다.
- 이미지와 소리는 그 자체로 숫자 데이터 => 연산이 가능하다
    - text는 숫자 데이터가 아니고, sparse한 데이터이다(onehot으로 바꾸니까)
    - nlp의 많은 문제들이 이 점에서 발생한다.
- CBOW를 이용하여 단어를 dense하게 표현해주자
    - distributional hypothesis
        - 단어 주변의 분포가 비슷하면 그 단어는 서로 비슷한 의미의 단어이다
    - 벡터간의 연산이 의미적인 연산으로 바뀔 수 있다.
    - Word2vec, Glove, fastText, Swivel
- 신조어 또는 조사의 영향 받지 않고 dense하게 표현할 수 없을까
    - sobwords
        - 두 글짜씩, 세 글짜씩 보는 방법
            - (짱이, 이에, 에요)
- Transformer
    - attention을 이용하자
- BERT
    - NLP에서는 label 달린 데이터가 필요하다는 한계가 있고 이를 해결하고자 하는 숙원이 있었다.
    - unlabel된 데이터를 활용할 수 있다면 모델을 크게 발전시킬 수 있겠다는 궁극의 성배 느낌
        - 이미지쪽에서는 이게 잘 되었다.  => Transfer learning
            - 1000개짜리 분류 모델을 두 개짜리 분류에 써도 잘 적용되었다.
    - 긴 글에 몇 개 단어를 뚫어놓고 낱말 맞추기 게임을 하면 그 과정에서 언어를 좀 더 이해할 수 있게 되지 않을까?
        - 이것의 장점은 이 word puzzle은 공짜다. 이런 데이터는 널려있다.
        - 이것을 이용해서 문장의 vector를 만들 수 있다.
    - how
        - semi-supervised 하게 큰 글에 대해서 learning 한다.
        - supervised training으로 특정 label 데이터에 적용한다.
    - BERT는 transformer를 아주 약간 바꾼 것.
- ELMO
- cf) multitask learning
    - 다양한 task를 하나의 모델로 같이 하면 더 좋아진다.
